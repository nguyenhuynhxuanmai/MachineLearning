{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 2\n",
    "\n",
    "---\n",
    "Mục tiêu chính ở đây là <font color=green>học, học một cách chân thật</font>; nếu bạn được 5 điểm nhưng bạn làm bài một cách chân thật thì vẫn tốt hơn nhiều so với 10 điểm mà không chân thật. Bạn có thể thảo luận với các bạn khác (nên tận dụng moodle), nhưng <font color=green>bài làm và code phải là của chính bạn, dựa trên sự hiểu của chính bạn</font>. <font color=red>Nếu vi phạm thì bạn sẽ bị 0 điểm cho toàn bộ môn học</font>.\n",
    "\n",
    "Một số lời khuyên khác:\n",
    "- Nên bắt đầu làm sớm, đừng đợi đến gần deadline.\n",
    "- Nên in các file bài tập của Caltech ra (trong môn học, mình sẽ làm 6 bài tập đầu tiên).\n",
    "- Làm từ từ, cẩn thận. Chậm là nhanh, nhanh là chậm.\n",
    "- Tránh xa các nguồn gây nhiễu; ví dụ, facebook ;-)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đề bài "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn download file bài tập \"Homework 2\" (gồm 10 câu hỏi trắc nghiệm) và file đáp án \"Solution key 2\" :-) [ở đây](http://work.caltech.edu/homeworks.html). Với mỗi câu, bạn cần giải thích <font color=blue>tại sao bạn lại chọn đáp án này</font> (không được dùng phương pháp loại trừ). Với những câu mà phải code, bạn cố gắng viết code rõ ràng, dễ đọc (đặt tên biến gợi nhớ, comment những chỗ cần comment). File đáp án ở đây đóng vai trò \"correct output\", giúp bạn biết được là mình đã làm đúng hay chưa, để \"điều chỉnh lại bộ trọng số\". <font color=blue>Bạn nên tự mình làm trước rồi sau đó mới check file đáp án; như vậy sẽ tốt hơn cho việc học của bạn</font>.\n",
    "\n",
    "Bạn sẽ làm bài trên file notebook \"HW2-Submission.ipynb\" mà mình đã cung cấp sẵn. Đầu tiên, bạn điền MSSV và họ tên vào đầu file. Với mỗi câu, mình đã để sẵn một markdown cell mà có ghi là \"YOUR ANSWER HERE\" để bạn làm (khi làm thì bạn có thể xóa dòng \"YOUR ANSWER HERE\" đi). Với mỗi câu, đầu tiên bạn sẽ trình bày các giải thích, và cuối cùng thì chốt lại là bạn chọn đáp án nào (ví dụ, bạn có thể ghi là \"Do đó, em chọn đáp án [d] abcxyz\"). Với mỗi câu, nếu cần thì bạn có thể chèn thêm các cell (code/markdown) ở <font color=blue>ngay trên</font> (không chèn dưới) cell \"YOUR ANSWER HERE\". Ví dụ:\n",
    "\n",
    "Câu 1 (1 điểm)\n",
    "- Cell bạn tự chèn\n",
    "- ...\n",
    "- Cell bạn tự chèn\n",
    "- Cell \"YOUR ANSWER HERE\" (ở cell này ít nhất là có dòng chốt về đáp án bạn chọn)\n",
    "\n",
    "Mình qui định như trên là vì khi chấm bài mình sẽ dùng một chương trình để hỗ trợ quá trình duyệt qua các bài, để có thể chấm nhanh hơn. Mặc dù bạn thấy cell \"YOUR ANSWER HERE\" không có gì đặc biệt, nhưng thật ra là cell này có những thông tin ẩn bên dưới để chương trình hỗ trợ chấm của mình có thể sử dụng. Do đó, <font color=red>bạn lưu ý tuân thủ đúng qui định của mình</font>.\n",
    "\n",
    "**Nộp bài:**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn \"Kernel\" - \"Restart & Run All\" để restart và chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử \"Kernel\" - \"Restart & Run All\" để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Nếu không có vấn đề gì thì bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "- Thư mục MSSV (ví dụ, nếu MSSV của bạn là 1234567 thì bạn đặt tên thư mục là 1234567):\n",
    "    - File \"HW2-Submission.ipynb\"\n",
    "\n",
    "Sau đó, bạn nén thư mục MSSV lại và nộp ở link trên moodle. Đuôi của file nén phải là .zip (chứ không được .rar hay gì khác).\n",
    "\n",
    "Một lần nữa, <font color=red>bạn lưu ý tuân thủ chính xác qui định nộp bài này để chương trình hỗ trợ chấm của mình có thể chạy được</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hướng dẫn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn nên tự làm trước, rồi sau đó mới xem hướng dẫn; mình nghĩ như vậy là tốt nhất cho việc học của bạn. Một câu thì có thể có nhiều cách giải, bạn không nhất thiết là phải làm theo cách mà mình hướng dẫn.\n",
    "\n",
    "Không phải tất cả các câu đều sẽ có hướng dẫn (phần hướng dẫn chủ yếu tập trung vào các câu liên quan đến lập trình). Nếu vẫn có thắc mắc gì khác thì bạn có thể post lên moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 1-2: Hoeffding Inequality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để dễ hình dung, có thể liên hệ bài này với ví dụ về bin như sau:\n",
    "- 1000 fair coin ứng với 1000 bin, mỗi bin có $\\mu=0.5$\n",
    "- Tung mỗi coin 10 lần ứng với lấy ra một sample có $N=10$, $\\nu$ là tỉ lệ mặt head trong $N=10$ lần tung. Theo ý của bđt Hoeffding thì nhiều khả năng là $\\nu$ sẽ gần với $\\mu$.\n",
    "- Với một coin (một bin), \"nhiều khả năng là $\\nu$ sẽ gần với $\\mu$\" nghĩa là sao? Nghĩa là: nếu ta lặp lại thí nghiệm này (lấy ra một sample có $N=10$) nhiều lần thì hầu hết các lần đều cho các sample có $\\nu$ gần với $\\mu$ (lâu lâu xui quá thì mới ra một sample mà gồm hầu hết là mặt head hoặc hầu hết là mặt tail). Đề bài yêu cầu lặp lại thí nghiệm 100,000 lần."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong Numpy (thường được import và đặt lại tên là `np`), ta có thể tạo ra các kết quả cho toàn bộ thí nghiệm ở trên bằng một dòng code:\n",
    "    \n",
    "    nus = np.random.binomial(N, mu, (n_repeats, n_coins)) / N\n",
    "\n",
    "Trong bài của mình, `N` = 10, `mu` = 0.5, `n_repeats` = 100,000, `n_coins` = 1000. Câu lệnh này sẽ tạo ra một mảng `nus` có kích thước là `n_repeats` dòng và `n_coins` cột. Trong đó, giá trị của mỗi phần tử trước khi chia cho `N` là: số lượng mặt head khi tung một coin `N` lần, coin có xác suất được mặt head là `mu`. Chia cho `N` thì sẽ ra được tỉ lệ mặt head $\\nu$. Như vậy, ta hiểu mỗi cột của mảng kết quả `nus` là ứng với các $\\nu$ của một coin khi thực hiện `n_repeats` lần thí nghiệm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Lấy ra mảng (một chiều) các $\\nu$ của coin $c_1$ (xem định nghĩa coin $c_1$ trong đề bài)?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siêu dễ :-). Chính là cột đầu tiên của mảng kết quả `nus` ở trên:\n",
    "\n",
    "    nus[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Lấy ra mảng (một chiều) các $\\nu$ của coin $c_{rand}$ (xem định nghĩa coin $c_{rand}$ trong đề bài)?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong Numpy, một cách để truy xuất các phần tử trong mảng 2 chiều là truy xuất với mảng chỉ số dòng và mảng chỉ số cột. Ví dụ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2, 3], [11, 12, 13]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 13]\n"
     ]
    }
   ],
   "source": [
    "# Giả sử ta muốn truy xuất: \n",
    "# - Phần tử 2 ở chỉ số dòng 0 và chỉ số cột 1 \n",
    "# - Phần tử 13 ở chỉ số dòng 1 và chỉ số cột 2\n",
    "rows = np.array([0, 1]) # Dùng list cũng được\n",
    "cols = np.array([1, 2])\n",
    "print(a[rows, cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để lấy ra mảng các $\\nu$ của coin $c_{rand}$ thì cần truy xuất `nus` với mảng chỉ số dòng nào và mảng chỉ số cột nào?\n",
    "- Mảng chỉ số dòng: gồm các phần tử 0, 1, ..., số dòng của `nus` trừ 1.\n",
    "\n",
    "        np.arange(nus.shape[0])\n",
    "- Mảng chỉ số cột: gồm số-dòng-của-`nus` phần tử, trong đó mỗi phần tử là một chỉ số cột ngẫu nhiên.\n",
    "        np.random.choice(np.arange(nus.shape[1]), size=nus.shape[0])\n",
    "Câu lệnh này tạo ra một mảng gồm `nus.shape[0]` phần tử, trong đó mỗi phần tử được chọn ngẫu nhiên trong mảng `np.arange(nus.shape[1])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Lấy ra mảng (một chiều) các $\\nu$ của coin $c_{min}$ (xem định nghĩa coin $c_{min}$ trong đề bài)?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Không khó :-). Từ mảng kết quả `nus` ở trên, thực hiện lấy min theo trục ngang (trong Numpy, với mảng 2 chiều thì trục đứng là trục 0, trục ngang là trục 1):\n",
    "\n",
    "    np.min(nus, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Câu 1.** Tính giá trị trung bình của mảng các $\\nu$ của coin $c_{min}$?</font>\n",
    "\n",
    "Siêu dễ, dùng `np.mean(...)` là xong.\n",
    "\n",
    "<font color=blue>**Câu 2.** Coin nào tuân theo bđt Hoeffding?</font>\n",
    "\n",
    "Cách đơn giản nhất là tính giá trị $\\nu$ trung bình của các coin và xem coin nào có giá trị $\\nu$ trung bình gần với $\\mu$ thì nói là thỏa bđt Hoeffding. Cách này không chặt chẽ lắm nhưng sẽ được chấp nhận và sẽ được 50% điểm của câu này (chỉ mất 0.5 điểm thôi).\n",
    "\n",
    "Cách chặt chẽ hơn (được full điểm) là với mỗi coin, bạn sẽ tính vế trái (VT) và vế phải (VP) của bđt Hoeffding và xem VT có $\\le$ VP không. Để tính được VT và VP thì bạn sẽ cần giá trị $\\epsilon$; ở đây $0<\\epsilon<0.5$, bạn xem đúng không? Như vậy, bạn sẽ tính VT và VP với nhiều giá trị $\\epsilon$ (ví dụ, bắt đầu với $0.01$ và cộng lên $0.01$ cho đến khi $< 0.5$); chỉ cần có một giá trị $\\epsilon$ mà VT > VP thì kết luận ngay là coin không thỏa bđt Hoeffding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 5-7: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây chỉ tập trung hướng dẫn về cài đặt thuật toán học/huấn-luyện của mô hình. Các phần như phát sinh hàm $f$, phát sinh dữ liệu, ... thì bạn có thể tham khảo trong phần hướng dẫn ở file \"HW1.ipynb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7cdbPhp068N",
    "toc-hr-collapsed": false
   },
   "source": [
    "***Linear Regression***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm huấn luyện Linear Regression**\n",
    "\n",
    "<font color=blue>Input của hàm </font>\n",
    "- `X`: mảng Numpy, kích thước $N\\times(d+1)$ với $N$ là số lượng mẫu huấn luyện, $d$ là số chiều của véc-tơ input (chưa tính thành phần $x_0=1$). Mỗi dòng của `X` ứng với một véc-tơ input (đã có $x_0$).\n",
    "- `ys`: mảng Numpy, kích thước $N\\times1$. `ys` chứa các output đúng tương ứng với các véc-tơ input trong `X`.\n",
    "\n",
    "<font color=blue>Output của hàm</font>\n",
    "\n",
    "`w`: mảng Numpy, kích thước $(d+1)\\times1$. `w` chính là véc-tơ trọng số của final hypothesis $g$.\n",
    "\n",
    "<font color=blue>Quá trình thực hiện</font>\n",
    "\n",
    "Như đã học, với Linear Regression (và độ lỗi bình phương), ta có thể nhanh chóng tìm được `w`:\n",
    "\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(X.T, X)), X.T)\n",
    "    w = np.dot(X_dagger, ys)\n",
    "Để đề phòng trường hợp `np.dot(X.T, X)` không khả nghịch (thực ra thì trường hợp này ít khi xảy ra trong thực tế), ta có thể thay hàm `np.linalg.inv` bằng `np.linalg.pinv`; trong trường hợp không khả nghịch thì hàm `pinv` sẽ tính ma trận nghịch đảo \"giả\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nói thêm: dùng $w$ có được để dự đoán các output của các véc-tơ input**\n",
    "\n",
    "Với một mảng `X` mà mỗi dòng là một véc-tơ input (`X` này có thể là của tập train, cũng có thể là của tập test), ta có thể dễ dàng tính được các output dự đoán tương ứng:\n",
    "    \n",
    "    predictions = np.dot(X, w)\n",
    "Nếu đang dùng Linear Regression cho bài toán phân 2 lớp (như trong bài này) thì cần lấy dấu của mảng `prediction` ở trên bằng hàm `np.sign(...)` (khi huấn luyện thì mọi chuyện vẫn như ở trên, không lấy dấu gì cả, chỉ lấy dấu khi dự đoán sau khi huấn luyện thôi).\n",
    "\n",
    "**Nói thêm: tính độ lỗi nhị phân trung bình giữa mảng output đúng và mảng output dự đoán**\n",
    "\n",
    "Siêu dễ:\n",
    "\n",
    "    np.mean(ys != predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7cdbPhp068N",
    "toc-hr-collapsed": false
   },
   "source": [
    "***Perceptron***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CIFjuucI068X"
   },
   "source": [
    "**Hàm huấn luyện Perceptron (thuật toán PLA)**\n",
    "\n",
    "<font color=blue>Input của hàm </font>\n",
    "- `X`: mảng Numpy, kích thước $N\\times(d+1)$ với $N$ là số lượng mẫu huấn luyện, $d$ là số chiều của véc-tơ input (chưa tính thành phần $x_0=1$). Mỗi dòng của `X` ứng với một véc-tơ input (đã có $x_0$).\n",
    "- `ys`: mảng Numpy, kích thước $N\\times1$. `ys` chứa các output đúng tương ứng với các véc-tơ input trong `X`.\n",
    "\n",
    "<font color=blue>Output của hàm</font>\n",
    "\n",
    "- `w`: mảng Numpy, kích thước $(d+1)\\times1$. `w` chính là véc-tơ trọng số của final hypothesis $g$.\n",
    "- `n_iterations`: số nguyên cho biết số vòng lặp đã được thực hiện (vì đề bài hỏi về giá trị này nên mới cần output ra). \n",
    "\n",
    "<font color=blue>Quá trình thực hiện</font>\n",
    "- Khởi tạo mảng `w` (có thể khởi tạo là mảng toàn 0 như ở bài tập 1, hoặc là mảng có được từ Linear Regression như ở bài tập này).\n",
    "- Khởi tạo `n_iterations` bằng 0.\n",
    "- Lặp:\n",
    "    - Tính `predictions` - mảng các output dự đoán có kích thước $N\\times1$ - từ  mảng `X` và mảng `w` hiện tại.\n",
    "    - Tính `errs` - mảng các giá trị lỗi nhị phân có kích thước $N\\times1$ - từ mảng `predictions` và mảng `ys`.\n",
    "    - Tính `mean_err` - giá trị độ lỗi nhị phân trung bình - từ mảng `errs`. *Nếu `mean_err` bằng 0 thì thoát ra khỏi vòng lặp!*\n",
    "    - Tính `rand_err_idx` - chỉ số của một mẫu bị lỗi *được chọn ngẫu nhiên* - từ mảng `errs`. Gợi ý: bạn có thể dùng hàm [np.flatnonzero](https://www.numpy.org/devdocs/reference/generated/numpy.flatnonzero.html?highlight=nonzero#numpy.flatnonzero) để tìm mảng các chỉ số của các mẫu bị lỗi, rồi sau đó dùng hàm [np.random.choice](https://www.numpy.org/devdocs/reference/generated/numpy.random.choice.html?highlight=random%20choice#numpy.random.choice) để chọn ra một giá trị ngẫu nhiên trong mảng các chỉ số này.\n",
    "    - Cập nhật lại mảng `w` dựa vào chỉ số `rand_err_idx` (xem lại công thức cập nhật trong slide).\n",
    "    - Cập nhật `n_iterations`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 8-10: Nonlinear Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thêm nhiễu vào tập dữ liệu**\n",
    "\n",
    "Đề bài yêu cầu thêm nhiễu vào dữ liệu bằng cách chọn ngẫu nhiên 10% các giá trị output đúng $y$ và đổi dấu của $y$. Để làm điều này, đầu tiên ta có thể phát sinh ra một mảng gồm `int(0.1*N)` chỉ số, mỗi chỉ số được lấy ngẫu nhiên từ 0, 1, ..., $N$ - 1 (các chỉ số không được trùng nhau):\n",
    "\n",
    "    np.random.choice(np.arange(N), size=int(0.1*N), replace=False)\n",
    "Bạn có thể xem thông tin về hàm `np.random.choice` trong [document](https://www.numpy.org/devdocs/reference/generated/numpy.random.choice.html?highlight=random%20choice#numpy.random.choice).\n",
    "\n",
    "Sau khi có được mảng các chỉ số này rồi thì ta có thể dùng nó để truy xuất các giá trị trong mảng `ys` và đổi dấu.\n",
    "\n",
    "**Dùng Nonlinear Transformation cho mô hình Linear Regression**\n",
    "\n",
    "- Đầu tiên, cần định nghĩa hàm chuyển từ mảng `X` gồm các véc-tơ input $x$ ban đầu sang mảng `Z` gồm các véc-tơ đặc trưng $z$. Theo đề, $z = [1, x_1, x_2, x_1x_2, x_1^2, x_2^2]^T$. \n",
    "- Khi huấn luyện thì đầu tiên dùng hàm ở trên để chuyển từ mảng `X` của tập train sang mảng `Z`, rồi sau đó gọi hàm huấn luyện Linear Regression với mảng các véc-tơ input là `Z` (thay vì `X`).\n",
    "- Khi dự đoán với một mảng `X` gồm các véc-tơ input thì đầu tiên dùng hàm ở trên để chuyển từ mảng `X` sang mảng `Z` rồi dự đoán một cách bình thường với mảng các véc-tơ input là `Z` (thay vì `X`).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
